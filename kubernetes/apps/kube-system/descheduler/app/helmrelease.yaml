---
apiVersion: source.toolkit.fluxcd.io/v1
kind: OCIRepository
metadata:
  name: descheduler
spec:
  interval: 5m
  layerSelector:
    mediaType: application/vnd.cncf.helm.chart.content.v1.tar+gzip
    operation: copy
  ref:
    tag: 0.33.0
  url: oci://ghcr.io/home-operations/charts-mirror/descheduler
  verify:
    provider: cosign
---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: descheduler
spec:
  interval: 1h
  chartRef:
    kind: OCIRepository
    name: descheduler
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      strategy: rollback
      retries: 3
  values:
    replicas: 2
    kind: Deployment
    deschedulerPolicyAPIVersion: descheduler/v1alpha2
    deschedulerPolicy:
      profiles:
        - name: Default
          pluginConfig:
            - name: DefaultEvictor
              args:
                evictFailedBarePods: true
                evictLocalStoragePods: true
                evictSystemCriticalPods: false # Changed to false for safety
                nodeFit: true # Ensure evicted pods can be scheduled elsewhere
            - name: RemoveFailedPods
              args:
                reasons:
                  - ContainerStatusUnknown
                  - NodeAffinity
                  - NodeShutdown
                  - Terminated
                  - UnexpectedAdmissionError
                includingInitContainers: true
                excludeOwnerKinds:
                  - Job
                minPodLifetimeSeconds: 1800
            - name: RemovePodsViolatingInterPodAntiAffinity
            - name: RemovePodsViolatingNodeAffinity
              args:
                nodeAffinityType:
                  - requiredDuringSchedulingIgnoredDuringExecution
            - name: RemovePodsViolatingNodeTaints
            - name: RemovePodsViolatingTopologySpreadConstraint
            - name: LowNodeUtilization # Added strategy
              args:
                thresholds:
                  pods: 20 # Nodes with <20% pod capacity are underutilized
                targetThresholds:
                  pods: 50 # Nodes with >50% pod capacity are overutilized
                useDeviationThresholds: true # Compare nodes based on deviation
                numberOfNodes: 3 # Ensure all nodes (m0, m1, m2) are considered
          plugins:
            balance:
              enabled:
                - RemovePodsViolatingTopologySpreadConstraint
                - LowNodeUtilization # Added to balance plugin
            deschedule:
              enabled:
                - RemoveFailedPods
                - RemovePodsViolatingInterPodAntiAffinity
                - RemovePodsViolatingNodeAffinity
                - RemovePodsViolatingNodeTaints
    service:
      enabled: true
    serviceMonitor:
      enabled: true
    leaderElection:
      enabled: true